#Aquatic Vegetation Project Work Team
#Master data set
#Submersed aquatic vegetation
#CSTARS ground truthing
#2022FranksTract

#Nick Rasmussen
#nicholas.rasmussen@water.ca.gov

#to do list

#species called "leafy sago" in notes is probably P. nodosus according to UCD
#figure out what it means when a spp is listed but with 0% rake cover (a common result)
  #are these trace amount spp?
#drop rows generated by structural zeros 
  #ie: rake_teeth_corr > 0 & species = NA & rake_prop=0
#consider adding column that indicates whether any SAV was collected
  #eg, 0 = open water, 1 = sav present

# Packages--------
library(tidyverse) #suite of data science tools
library(sf) #work with GPS coordinates
library(janitor) #make column names tidier
library(foreign) #read dbf files
library(hms) #formatting time
library(lubridate) #formatting dates

# Read in the data----------------------------------------------
franks22 <- read.dbf("Data_Raw/CSTARS_GroundTruthing/FranksTract_2022/FTgrid_2022_distance.dbf")
glimpse(franks22)

#reduce data set to just the columns I need
ft22 <- franks22 %>% 
  #use janitor function to clean up column names
  clean_names() %>% 
  rename(
    ucd_id = point_id
    ,sepro_id = gri_did
    #CSTARS said the distances are in meters
    ,pt_dist_m = near_dist
    ,date = gps_date
    ,time = gps_time
    ,feat = feat_name 
    #CRS is UTM NAD 83 (Zone 10N) (EPSG = 26910)
    ,northing_26910 = northing
    ,easting_26910 = easting
    ) %>% 
  #removes all % from data frame but converts all columns to character which is a hassle
  #mutate_all(str_replace_all, "%", "")
  #instead remove % from specific columns and make those columns numeric
  mutate(rake_teeth = str_replace(rake_teeth,pattern = "%", replacement = "")
         ,rake_spec2 = str_replace(rake_spec2,pattern = "%", replacement = "") 
         ,rake_spec4 = str_replace(rake_spec4,pattern = "%", replacement = "")
         ,rake_spec6 = str_replace(rake_spec6,pattern = "%", replacement = "")
         ,rake_spec8 = str_replace(rake_spec8,pattern = "%", replacement = "")
         ,rake_spe10 = str_replace(rake_spe10,pattern = "%", replacement = "")
         ,across(c(rake_teeth,rake_spec2,rake_spec4,rake_spec6, rake_spec8, rake_spe10),as.numeric)
  ) %>% 
  #create new column that calculates total rake coverage of spp
  #should all be either 0 or 100; most but not all of them are, indicating some errors
  rowwise() %>% 
  mutate(tot_cover_spp = sum(c(rake_spec2,rake_spec4,rake_spec6, rake_spec8, rake_spe10),na.rm=T)) %>% 
  #make new columns that will allow for comparison of rake coverage to spp level coverage
  #values for rake_teeth_logical and tot_cover_spp_logical should match
  #ie, both be zero or both be one; mismatch often indicates errors
  mutate(rake_teeth_logical = if_else(rake_teeth > 0, 1,0)
         ,tot_cover_spp_logical = if_else(tot_cover_spp > 0, 1,0)
         ,rake_diff = abs(rake_teeth_logical-tot_cover_spp_logical)
         #there are five samples indicating a difference (ie, possible error)
         #ucd #24: replace one incorrect case of rake_teeth=100% to rake_teeth=0% 
         #confirmed this error with CSTARS
         ,rake_teeth_corr = if_else((rake_diff==1 & is.na(rake_speci)),0,rake_teeth)
         #ucd #29: replace one incorrect case of southern naiad listed as 0% when should be 100%
         #confirmed this error with CSTARS
         ,rake_spec2_corr = ifelse(ucd_id == 29, 100,rake_spec2)
         #the other three samples were trace amounts of spp so rake teeth was entered at 0%
         #even though there were species present
         ) %>% 
  arrange(rake_diff) %>% 
  select(ucd_id
         ,sepro_id
         ,pt_dist_m
         ,northing_26910
         ,easting_26910
         ,date
         ,time
         ,feat
         ,rake_teeth_corr
         ,rake_speci
         ,rake_spec2_corr
         ,rake_spec3:rake_spe10
         ,rake_diff
  ) %>%
  glimpse()

#create data frame with errors in rake data
#sent to CSTARS on 8/31/22 for clarification
#errors <- ft22 %>% 
 # filter(rake_diff != 0)
#write_csv(errors,"Data_Raw/CSTARS_GroundTruthing/FranksTract_2022/FranksTract2022_DataIssues.csv")

#convert data frame from wide to long
ft_long <- ft22 %>% 
  #drop some unneeded columns
  select(-c(rake_diff)) %>% 
  #in prep for converting wide-ish to longest, rename some columns
  rename(rake_teeth = rake_teeth_corr
         ,rake_spec1 = rake_speci
         ,rake_prop1 = rake_spec2_corr
         ,rake_prop3 = rake_spec4
         ,rake_prop5 = rake_spec6
         ,rake_prop7 = rake_spec8
         ,rake_prop9 = rake_spe10
  )  %>% 
  #convert the rake prop columns back to factors for converting from wide to long
  mutate(across(c(rake_prop1,rake_prop3,rake_prop5,rake_prop7,rake_prop9),as.factor)) %>% 
  #convert wide to long
  pivot_longer(cols="rake_spec1":"rake_prop9" #select range of columns
               , names_to = c("name","num") #specify column names
               , names_pattern = '([^0-9]+)([0-9]+)' #indicate where to split names (before and after numbers)
               , values_to = "value")  %>% 
  glimpse()

ft_wide <- ft_long %>% 
  #now pivot back to a bit wider
  pivot_wider(names_from=name, values_from=value) %>% 
  #remove rows where species is NA 
  #these are just artifacts of original data structure
  #NOTE: this also drops three samples that aren't SAV (ie, FAV, EAV)
  #If a species is listed but has a rake prop = 0 it means trace amounts present
  filter(!(is.na(rake_spec))) %>%
  mutate(
    #make rake prop numeric instead of factor
    rake_prop = as.numeric(as.character(rake_prop))
    #fix one case in which a species is listed but rake prop is NA when it should be zero
    #indicating trace amounts of it on the rake
    ,rake_prop_corr = if_else((is.na(rake_prop)),0,rake_prop)
    )  %>% 
  #drop unneeded columns
  select(-c(num,rake_prop)) %>%
  rename(rake_prop = rake_prop_corr) %>% 
  glimpse()

# Making data frame with existing strings and their replacement
tr <- data.frame(target = c("SAV-S-naiad"        
                            ,"SAV-Egeria"
                            ,"SAV-Unknown"
                            ,"SAV-Elodea"
                            ,"SAV-Coontail"
                            ,"SAV-Watermilfoil"
                            ,"SAV-Rich-pondweed"
                            ,"SAV-Algae-mats"
                            ,"SAV-Sago-pondweed"  
                            ,"SAV-CrlLf-pondweed"
                            ,"SAV-Algae"
                            ,"SAV-Am-pondweed"    
                            ,"SAV-Cabomba"
                            ,"SAV-FnLf-pondweed"  
                            ,"SAV-Tapegrass"),
                 replacement = c("Najas_guadalupensis"        
                                 ,"Egeria_densa"
                                 ,"Unidentified"
                                 ,"Elodea_canadensis"
                                 ,"Ceratophyllum_demersum"
                                 ,"Myriophyllum_spicatum"
                                 ,"Potamogeton_richardsonii"
                                 ,"Algae"
                                 #confirmed with UCD this should be S. pectinata
                                 ,"Stuckenia_pectinata"  
                                 ,"Potamogeton_crispus"
                                 ,"Algae"
                                 ,"Potamogeton_nodosus"    
                                 ,"Cabomba_caroliniana" 
                                 ,"Stuckenia_filiformis"  
                                 ,"Vallisneria_australis"
                                 ))

# Making the named replacement vector from tr
replacements <- c(tr$replacement)
names(replacements) <- c(tr$target)

#continue formatting data set
ft_wider <- ft_wide %>% 
  #drop the SAV prefix from spp names
  mutate(species = str_replace_all(rake_spec,"SAV-","")) %>% 
  #drop unneeded columns
  select(-c(rake_spec,feat)) %>% 
  #pivot wider
  pivot_wider(names_from = "species", values_from = "rake_prop")  
  #change CRS of sample coordinates
  #specify the CRS of original coordinate
  #confirmed that it is UTM NAD 83 (Zone 10N) (EPSG = 26910)
  #st_as_sf(coords = c("easting", "northing"), crs = 26910) %>%
  #then transform to WGS84
  #st_transform(4236) %>% 
  #then convert from geometry to columns
  #mutate(latitude_wgs84 = unlist(map(geometry,2)),
   #      longitude_wgs84 = unlist(map(geometry,1))) %>% 
  #drop the geometry column
  #st_set_geometry(NULL) %>% 
  #mutate(across(c(time),as.character)) %>% 
  
#write final data frame to csv file
#write_csv(ft_wider,file = "Data_Raw/CSTARS_GroundTruthing/FranksTract_2022/FranksTract_2022_formatted.csv"))

  
  
  